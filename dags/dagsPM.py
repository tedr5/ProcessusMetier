from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.python_operator import BranchPythonOperator
from datetime import datetime, timedelta


default_args = {
    'owner': 'thomas',
    'start_date': datetime(2023, 2, 10),
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'dagPM',
    default_args=default_args,
    description='dag PM',
    schedule_interval=timedelta(days=1)
)





def create_dw(**kwargs):
    import psycopg2
    conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="pnhfwdno",
        user="pnhfwdno",
        password="oGp5JpxnuWD-Gh-Rtk31jnc-cMliqr5u"
    )
    cur = conn.cursor()
    # création des tables
    cur.execute("""CREATE TABLE IF NOT EXISTS tweets(
                    id_tweet   INT PRIMARY KEY,
                    id_author BIGINT NOT NULL,
                    sentiment VARCHAR(8) NOT NULL
                    )""")
    cur.execute("""CREATE TABLE IF NOT EXISTS tweets_topics(
                    id_tweet INT,
                    topic VARCHAR(150),
                    PRIMARY KEY(id_tweet, topic),
                    CONSTRAINT fk_tweet
                        FOREIGN KEY(id_tweet)
                            REFERENCES tweets(id_tweet)
                    )""")
    cur.execute("""CREATE TABLE IF NOT EXISTS tweets_hashtags(
                    id_tweet INT,
                    hashtag VARCHAR(50),
                    PRIMARY KEY(id_tweet, hashtag),
                    CONSTRAINT fk_tweet
                        FOREIGN KEY(id_tweet)
                            REFERENCES tweets(id_tweet)
                    )""")
    conn.commit()
    conn.close()
    print("Table created successfully")


def init_dl(**kwargs):
        import psycopg2
        from psycopg2.extras import Json
        import json
        conn = psycopg2.connect(
            host="manny.db.elephantsql.com",
            database="ooclcvaz",
            user="ooclcvaz",
            password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
        )
        cur = conn.cursor()
        # creation of the table in the database if it does not exist
        cur.execute("""CREATE TABLE IF NOT EXISTS t_json(
                    id   INT    GENERATED BY DEFAULT AS IDENTITY,
                    c_json   json)""")
        cur.execute("""CREATE UNIQUE INDEX IF NOT EXISTS on_id_tweets ON t_json( (c_json->>'id') ) ;""")
        # chargement du fichier json
        my_file = open("/home/tr/airflow/dags/file/versailles_tweets_100.json", encoding="utf-8")
        data = json.load(my_file)
        # insertion de tous les tuples avec clés générées automatiquement
        for index in range(len(data)):
            d = data[index]
            cur.execute("""INSERT INTO t_json (c_json) VALUES (%s) ON CONFLICT DO NOTHING""", [Json(d)])
        conn.commit()
        conn.close()  
  
def extract_from_db(**context):
    import psycopg2
    conn = psycopg2.connect(
            host="manny.db.elephantsql.com",
            database="ooclcvaz",
            user="ooclcvaz",
            password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
    )
    cur = conn.cursor()
    cur.execute("""SELECT * FROM t_json""")
    result = cur.fetchall()
    context['ti'].xcom_push(key='result', value=result)

def author_id(id_tweet):
    import psycopg2
    conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="ooclcvaz",
        user="ooclcvaz",
        password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
    )
    cur = conn.cursor()
    cur.execute("""SELECT c_json
                    FROM t_json
                    WHERE id = (%s)""", [id_tweet])
    row = cur.fetchone()
    conn.commit()
    conn.close()
    print("#######FINI AUTHOR ")
    dic = row[0]
    return dic['author_id']

def sentiment_analysis(id_tweet):
    import psycopg2
    from textblob import TextBlob
    conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="ooclcvaz",
        user="ooclcvaz",
        password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
    )
    cur = conn.cursor()
    cur.execute("""SELECT c_json
                        FROM t_json
                        WHERE id = (%s)""", [id_tweet])
    row = cur.fetchone()
    conn.commit()
    conn.close()
    dic = row[0]
    tweet = TextBlob(dic['text'])
    if tweet.sentiment.polarity >= 0:
        return "positive"
    return "negative"

def hashtag_extraction(id_tweet):
    import psycopg2
    conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="ooclcvaz",
        user="ooclcvaz",
        password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
    )
    cur = conn.cursor()
    cur.execute("""SELECT c_json
                        FROM t_json
                        WHERE id = (%s)""", [id_tweet])
    row = cur.fetchone()
    conn.commit()
    conn.close()
    dic = row[0]
    list_hashtags = []
    try:
        d = dic['entities']['hashtags']
        for index in range(len(d)):
            hashtag = d[index]['tag']
            list_hashtags.append(hashtag)
    except KeyError:
        pass
    for elt in list_hashtags:
        print("Les hashtags extraits: ", elt)
    print("###### FINI HASHTAGS:  ", list_hashtags)
    return list_hashtags


def topic_id(id_tweet):
    import psycopg2
    conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="ooclcvaz",
        user="ooclcvaz",
        password="4GtEGH2xmigXGU3lVd8_6NQEHbUUtTYq"
    )
    cur = conn.cursor()
    cur.execute("""SELECT c_json
                        FROM t_json
                        WHERE id = (%s)""", [id_tweet])
    row = cur.fetchone()
    conn.commit()
    conn.close()
    dic = row[0]
    list_topics = []
    try:
        d = dic['context_annotations']
        for index in range(len(d)):
            topic = d[index]['entity']['name']
            list_topics.append(topic)
    except KeyError:
        pass
    for elt in list_topics:
        print("Les topics extraits: ", elt)
    print("######## FINI TOPIC: ", list_topics)
    return list_topics

def all_authors(**context):
    result = context['ti'].xcom_pull(task_ids='extract_from_db', key='result')
    dict_all_authors = {}
    for row in result:
        id = row[0]
        author = author_id(id)
        dict_all_authors[id] = author
    print("########### ",dict_all_authors)
    context['ti'].xcom_push(key='all_authors', value=dict_all_authors)

def all_sentiment(**context):
    result = context['ti'].xcom_pull(task_ids='extract_from_db', key='result')
    dict_all_sentiment = {}
    for row in result:
        id = row[0]
        sentiment = sentiment_analysis(id)
        dict_all_sentiment[id] = sentiment
    print("########### ",dict_all_sentiment)
    context['ti'].xcom_push(key='all_sentiment', value=dict_all_sentiment)

def all_hashtags(**context):
    result = context['ti'].xcom_pull(task_ids='extract_from_db', key='result')
    dict_all_hashtags = {}
    for row in result:
        id = row[0]
        hashtags = hashtag_extraction(id)
        if hashtags:
            dict_all_hashtags[id] = hashtags 
    print("########### ",dict_all_hashtags)
    context['ti'].xcom_push(key='all_hashtags', value=dict_all_hashtags)

def all_topics(**context):
    result = context['ti'].xcom_pull(task_ids='extract_from_db', key='result')
    dict_all_topics = {}
    for row in result:
        id = row[0]
        topics = topic_id(id)
        if topics:
            dict_all_topics[id] = topics 
    print("########### ",dict_all_topics)
    context['ti'].xcom_push(key='all_topics', value=dict_all_topics)



def insert_dw(**context):
        import psycopg2
        conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="pnhfwdno",
        user="pnhfwdno",
        password="oGp5JpxnuWD-Gh-Rtk31jnc-cMliqr5u")
        conn.autocommit = True
        cursor_dw = conn.cursor()
        # insertion des tuples et/ou actualisation de la base de données
        authors = context['ti'].xcom_pull(task_ids='all_authors', key='all_authors')
        sentiment = context['ti'].xcom_pull(task_ids='all_sentiment', key='all_sentiment')
        hashtags = context['ti'].xcom_pull(task_ids='all_hashtags', key='all_hashtags')
        topics = context['ti'].xcom_pull(task_ids='all_topics', key='all_topics')

        for id in authors.keys():
            print("###########Dans le for!!")
            cursor_dw.execute("""INSERT INTO tweets(id_tweet, id_author, sentiment)
                            VALUES (%s, %s, %s)
                            ON CONFLICT DO NOTHING""", (id, authors[id], sentiment[id]))
            print("Tweet "+str(id) + " inserted successfully or already inserted")

        for id in hashtags.keys():
            for h in hashtags[id]: 
                cursor_dw.execute("""INSERT INTO tweets_hashtags(id_tweet, hashtag) 
                                    VALUES (%s, %s)
                                    ON CONFLICT DO NOTHING
                                """, (id, h))
                print("Pair tweet-hashtag Tweet " + str(id) + "---" + h + " --inserted successfully or already inserted")
         
        for id in topics.keys():
            for t in topics[id]:
                cursor_dw.execute("""INSERT INTO tweets_topics(id_tweet, topic) 
                                        VALUES (%s, %s)
                                        ON CONFLICT DO NOTHING
                                    """, (id, t))
                print("Couple tweet-topic Tweet " + str(id) + "---" + t + " --inserted successfully or already inserted")
        conn.close()
    


def publication_by_user(**kwargs):
        import psycopg2
        conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="pnhfwdno",
        user="pnhfwdno",
        password="oGp5JpxnuWD-Gh-Rtk31jnc-cMliqr5u"
        )
        cur = conn.cursor()
        cur.execute("""SELECT id_author, COUNT(*) AS nb_p
                        FROM tweets
                        GROUP BY id_author
                        """)
        result = cur.fetchall()
        conn.commit()
        conn.close()
        dic_users = {}
        try:
            for row in result:
                users = str(row[0])
                nb_p = row[1]
                dic_users["U" + users] = nb_p
                print(dic_users)
        except KeyError:
            pass
        return dic_users

def publication_by_hashtag(**kwargs):
        import psycopg2
        conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="pnhfwdno",
        user="pnhfwdno",
        password="oGp5JpxnuWD-Gh-Rtk31jnc-cMliqr5u"
        )
        cur = conn.cursor()
        cur.execute("""SELECT hashtag, COUNT(*) AS nb_p
                        FROM tweets_hashtags
                        GROUP BY hashtag
                        """)
        result = cur.fetchall()
        conn.commit()
        conn.close()
        dic_hashtags = {}
        try:
            for row in result:
                hashtags = row[0]
                nb_p = row[1]
                dic_hashtags[hashtags] = nb_p
                print(dic_hashtags)
        except KeyError:
            pass
        return dic_hashtags

def publication_by_topic(**kwargs):
        import psycopg2
        conn = psycopg2.connect(
        host="manny.db.elephantsql.com",
        database="pnhfwdno",
        user="pnhfwdno",
        password="oGp5JpxnuWD-Gh-Rtk31jnc-cMliqr5u"
        )
        cur = conn.cursor()
        cur.execute("""SELECT topic, COUNT(*) AS nb_p
                        FROM tweets_topics
                        GROUP BY topic
                        """)
        result = cur.fetchall()
        conn.commit()
        conn.close()
        dic_topics = {}
        try:
            for row in result:
                topics = row[0]
                topics = topics.replace(" ", "_")
                topics = topics.replace("&", "and")
                nb_p = row[1]
                dic_topics[topics] = nb_p
                print(dic_topics)
        except KeyError:
            pass
        return dic_topics


init_dl_task = PythonOperator(
    task_id='init_dl',
    python_callable=init_dl,
    dag=dag
)

create_dw_task = PythonOperator(
    task_id='create_dw',
    python_callable=create_dw,
    dag=dag
)

extract_task = PythonOperator(
    task_id='extract_from_db',
    python_callable=extract_from_db,
    provide_context=True,
    dag=dag
)



insert_dw_task = PythonOperator(
    task_id='insert_dw',
    python_callable=insert_dw,
    provide_context=True,
    dag=dag
)



all_authors_task = PythonOperator(
    task_id='all_authors',
    python_callable=all_authors,
    provide_context=True,
    dag=dag
)


all_sentiment_task = PythonOperator(
    task_id='all_sentiment',
    python_callable=all_sentiment,
    provide_context=True,
    dag=dag
)

all_hashtags_task = PythonOperator(
    task_id='all_hashtags',
    python_callable=all_hashtags,
    provide_context=True,
    dag=dag
)

all_topics_task = PythonOperator(
    task_id='all_topics',
    python_callable=all_topics,
    provide_context=True,
    dag=dag
)


publication_by_user_task = PythonOperator(
    task_id='publication_by_user_task',
    python_callable=publication_by_user,
    dag=dag
)

publication_by_hashtag_task = PythonOperator(
    task_id='publication_by_hashtag',
    python_callable=publication_by_hashtag,
    dag=dag
)

publication_by_topic_task = PythonOperator(
    task_id='publication_by_topic',
    python_callable=publication_by_topic,
    dag=dag
)

init_dl_task >> create_dw_task 
create_dw_task >> extract_task >> all_authors_task >> all_sentiment_task >> all_hashtags_task >> all_topics_task >> insert_dw_task 

insert_dw_task >>  publication_by_user_task
insert_dw_task >> publication_by_hashtag_task
insert_dw_task >> publication_by_topic_task